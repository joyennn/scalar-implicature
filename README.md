# scalar-implicature

 This study investigates how Large Language Models (LLMs), particularly BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic inference of scalar implicature, such as 'some'. Two sets of experiments were conducted to compare two sentences using cosine similarity and next sentence prediction. The results show that, in the absence of context, both models tend to interpret some as pragmatic implicature not all, aligning with human language processing. When Question Under Discussion (QUD) is presented as a contextual cue, BERT exhibits consistent performance regardless of the QUDs, while GPT-2 encounters processing difficulties when the QUD requires pragmatic implicature. In theoretical approaches, BERT inherently incorporates pragmatic implicature not all within the term some, adhering to a Default model (Levinson, 2000). In contrast, GPT-2 demonstrates a Context-driven model, suggesting an increased processing effort to infer pragmatic implicature within context (Sperber and Wilson, 2002).
